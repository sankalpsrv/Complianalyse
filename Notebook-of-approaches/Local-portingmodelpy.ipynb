{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d942539b-9806-4ae1-8ae6-b4b817d7b81e",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Considering that porting the inferencing from an Azure ML Endpoints workflow to a Local Workflow was required to be done [see earlier Notebook titled LocalLlama-LangChain which tested the various models and approaches](https://github.com/sankalpsrv/Schematise/blob/main/Notebook-of-approaches/LocalLlama-LangChain.ipynb)this notebook documents the process of alignment of the code so far with a Local inference workflow on a Cloud GPU endpoint with 24 GB RAM (GPU)\n",
    "\n",
    "### Contents\n",
    "[Part-1](#Part-1) Setup using GPTQ model from the Bloke -with instructions on HuggingFace model page.\n",
    "\n",
    "[Part-2](#Part-2) Porting the Send_request function using LangChain's FewShotChatMessagePromptTemplate class\n",
    "\n",
    "[Part-3-A](#Part-3-A) Trying an approach for prompting using SystemMessagePromptTemplate\n",
    "\n",
    "[Part-3-B](#Part-3-B) Prompting the ChatPromptTemplate by adding System Prompt to Llama2's instruction prompt\n",
    "\n",
    "### Results\n",
    "\n",
    "1. The context length for prompting using SystemMessagePromptTemplate was lesser than when using the Llama2 Instruction Prompt Template in the \"Human Message\". This signified that the context was missing. Hence, it the latter strategy yields better results (see last cell)\n",
    "\n",
    "2. Setting up a pipeline with parameters may have to be reconsidered in light of the warning message and deprecation.\n",
    "\n",
    "3. While the send_request function was successfully ported, further strategies may involve using ExampleSelector on LangChain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8944060-6552-47e2-b0d1-4b6b2a2eaa70",
   "metadata": {},
   "source": [
    "### Part-1\n",
    "\n",
    "Setup using GPTQ model from the Bloke -with instructions on HuggingFace model page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376e2fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/Schematise-dev-server/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "def instantiate_model():\n",
    "    model_name_or_path = \"TheBloke/Llama-2-7B-Chat-GPTQ\"\n",
    "    # To use a different branch, change revision\n",
    "    # For example: revision=\"main\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                                 device_map=\"auto\",\n",
    "                                                 trust_remote_code=True,\n",
    "                                                 revision=\"main\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=4000,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        repetition_penalty=1.1\n",
    "    )\n",
    "    hf = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "    return hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907c9da-d383-4802-99a4-6492427ca442",
   "metadata": {},
   "source": [
    "### Part-2 \n",
    "\n",
    "Porting the Send_request function using LangChain's FewShotChatMessagePromptTemplate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7042e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def send_request(hf, section_for_conversion):\n",
    "        examples = [\n",
    "            {\n",
    "                \"question\": \"Convert this statute extract to Legal Rule ML XML format: The benefit referred to in comma 1 shall be paid in an amount equal 80 per cent of five-twelfths of the income earned and reported for tax purposes by the freelancer in the second year preceding the year of application.\",\n",
    "                \"answer\": \"\"\"<lrml:ConstitutiveStatement key=\"tax2\">\n",
    "\n",
    "          <ruleml:Rule closure=\"universal\">\n",
    "\n",
    "        <lrml:Paraphrase>If income is reported in some year, then it was earned in the previous year.\n",
    "\n",
    "        </lrml:Paraphrase>\n",
    "\n",
    "        <ruleml:if>\n",
    "\n",
    "          <ruleml:Atom>\n",
    "\n",
    "            <ruleml:Rel iri=\":reported\"/>\n",
    "\n",
    "            <ruleml:Var>income</ruleml:Var>\n",
    "\n",
    "            <ruleml:Var>year</ruleml:Var>\n",
    "\n",
    "          </ruleml:Atom>\n",
    "\n",
    "        </ruleml:if>\n",
    "\n",
    "        <ruleml:then>\n",
    "\n",
    "          <ruleml:Atom>\n",
    "\n",
    "            <ruleml:Rel iri=\":earned\"/>\n",
    "\n",
    "            <ruleml:Var>income</ruleml:Var>\n",
    "\n",
    "            <ruleml:Expr key=\":year-1\">\n",
    "\n",
    "              <ruleml:Fun iri=\":subtract\"/>\n",
    "\n",
    "              <ruleml:Var>year</ruleml:Var>\n",
    "\n",
    "              <ruleml:Data xsi:type=\"xs:integer\">1</ruleml:Data>\n",
    "\n",
    "            </ruleml:Expr>\n",
    "\n",
    "          </ruleml:Atom>\n",
    "\n",
    "        </ruleml:then>\n",
    "\n",
    "      </ruleml:Rule>\n",
    "\n",
    "    </lrml:ConstitutiveStatement>\n",
    "    <lrml:PrescriptiveStatement key=\"literal\">\n",
    "\n",
    "    <ruleml:Rule closure=\"universal\" key=\":literal-template\">\n",
    "\n",
    "        <ruleml:if>\n",
    "\n",
    "            <ruleml:And>\n",
    "\n",
    "                <ruleml:Atom key=\":atom-earned\">\n",
    "\n",
    "                    <ruleml:Rel iri=\":earned\"/>\n",
    "\n",
    "                     <ruleml:Var>income</ruleml:Var>\n",
    "\n",
    "                     <ruleml:Expr>\n",
    "\n",
    "                        <ruleml:Fun iri=\":subtract\"/>\n",
    "\n",
    "                        <ruleml:Var>year</ruleml:Var>\n",
    "\n",
    "                        <ruleml:Data xsi:type=\"xs:integer\">2</ruleml:Data>\n",
    "\n",
    "                     </ruleml:Expr>\n",
    "\n",
    "                 </ruleml:Atom>\n",
    "\n",
    "                 <ruleml:Atom key=\":atom-reported\">\n",
    "\n",
    "                     <ruleml:Rel iri=\":reported\"/>\n",
    "\n",
    "                     <ruleml:Var>income</ruleml:Var>\n",
    "\n",
    "                    <ruleml:Expr>\n",
    "\n",
    "                         <ruleml:Fun iri=\":subtract\"/>\n",
    "\n",
    "                         <ruleml:Var>year</ruleml:Var>\n",
    "\n",
    "                         <ruleml:Data xsi:type=\"xs:integer\">2</ruleml:Data>\n",
    "\n",
    "                     </ruleml:Expr>\n",
    "\n",
    "                 </ruleml:Atom>\n",
    "\n",
    "            </ruleml:And>\n",
    "\n",
    "        </ruleml:if>\n",
    "\n",
    "        <ruleml:then>\n",
    "\n",
    "             <lrml:Obligation key=\"obl-paybenefit\">\n",
    "\n",
    "                  <ruleml:slot>\n",
    "\n",
    "                      <lrml:Bearer/>\n",
    "\n",
    "                      <ruleml:Var>Employer</ruleml:Var>\n",
    "\n",
    "                  </ruleml:slot>\n",
    "\n",
    "                  <ruleml:slot>\n",
    "\n",
    "                      <lrml:AuxiliaryParty/>\n",
    "\n",
    "                      <ruleml:Var>Freelancer</ruleml:Var>\n",
    "\n",
    "                  </ruleml:slot>\n",
    "\n",
    "                  <ruleml:Atom>\n",
    "\n",
    "                      <ruleml:Rel iri=\":paybenefit\"/>\n",
    "\n",
    "                     <ruleml:Expr>\n",
    "\n",
    "                          <ruleml:Fun iri=\":80_percent_of_five-twelfths_of\"/>\n",
    "\n",
    "                          <ruleml:Var>income</ruleml:Var>\n",
    "\n",
    "                      </ruleml:Expr>\n",
    "\n",
    "                      <ruleml:Var>year</ruleml:Var>\n",
    "\n",
    "                  </ruleml:Atom>\n",
    "\n",
    "              </lrml:Obligation>\n",
    "\n",
    "          </ruleml:then>\n",
    "\n",
    "      </ruleml:Rule>\n",
    "\n",
    "</lrml:PrescriptiveStatement>\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"question\": \"Convert this statute extract to Legal Rule ML XML format:A person must not engage in a credit activity if the person does not hold a licence authorising the person to engage in the credit activity. Civil penalty: 2,000 penalty units.  Criminal penalty: 200 penalty units, or 2 years imprisonment, or both.\",\n",
    "                \"answer\": \"\"\"\n",
    "                <lrml:LegalSources>\n",
    "\n",
    "   <lrml:LegalSource key=\"ls1\"             sameAs=\"http://www.comlaw.gov.au/Details/C2009A00134/Html/Text#param43\"/>\n",
    "\n",
    "</lrml:LegalSources>\n",
    "\n",
    "\n",
    "<lrml:Context key=\"psInfo1\">\n",
    "\n",
    "   <lrml:appliesAssociations>\n",
    "\n",
    "          <lrml:Associations>\n",
    "\n",
    "                <lrml:Association>\n",
    "\n",
    "                       <lrml:appliesSource keyref=\"#ls1/>\n",
    "\n",
    "                       <lrml:toTarget keyref=\"#ps1\"/>\n",
    "\n",
    "                       <lrml:toTarget keyref=\"#ps2\"/>\n",
    "\n",
    "                       <lrml:toTarget keyref=\"#pen1\"/>\n",
    "\n",
    "                       <lrml:toTarget keyref=\"#pen2\"/>\n",
    "\n",
    "                </lrml:Association>\n",
    "\n",
    "          </lrml:Associations>\n",
    "\n",
    "</lrml:appliesAssociations>\n",
    "\n",
    "</lrml:Context>\n",
    "\n",
    "\n",
    "<lrml:Statements key=\"textblock1\">\n",
    "\n",
    "<lrml:hasQualification>\n",
    "\n",
    "  <lrml:Override over=\"#ps2\" under=\"#ps1\"/>\n",
    "\n",
    "  </lrml:hasQualification>\n",
    "\n",
    "  <lrml:PrescriptiveStatement key=\"ps1\">\n",
    "\n",
    "      <ruleml:Rule key=\":rule1\" closure=\"universal\">\n",
    "\n",
    "        <lrml:hasStrength>\n",
    "\n",
    "          <lrml:DefeasibleStrength key=\"str1\" iri=\"&defeasible-ontology;#defeasible1\"/>\n",
    "\n",
    "        </lrml:hasStrength>\n",
    "\n",
    "        <ruleml:if>\n",
    "\n",
    "          <ruleml:Atom>\n",
    "\n",
    "            <ruleml:Rel iri=\":person\"/>\n",
    "\n",
    "            <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "          </ruleml:Atom>\n",
    "\n",
    "        </ruleml:if>\n",
    "\n",
    "        <ruleml:then>\n",
    "\n",
    "          <lrml:SuborderList>\n",
    "\n",
    "            <lrml:Prohibition>\n",
    "\n",
    "              <ruleml:Atom>\n",
    "\n",
    "                <ruleml:Rel iri=\":engageCreditActivity\"/>\n",
    "\n",
    "                <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "              </ruleml:Atom>\n",
    "\n",
    "            </lrml:Prohibition>\n",
    "\n",
    "          </lrml:SuborderList>\n",
    "\n",
    "        </ruleml:then>\n",
    "\n",
    "      </ruleml:Rule>\n",
    "\n",
    "    </lrml:PrescriptiveStatement>\n",
    "\n",
    "\n",
    "\n",
    "    <lrml:PenaltyStatement key=\"pen2\">\n",
    "\n",
    "      <lrml:SuborderList>\n",
    "\n",
    "        <lrml:Obligation>\n",
    "\n",
    "          <ruleml:Atom>\n",
    "\n",
    "            <ruleml:Rel iri=\":payPenalUnits\"/>\n",
    "\n",
    "            <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "            <ruleml:Ind>200</ruleml:Ind>\n",
    "\n",
    "          </ruleml:Atom>\n",
    "\n",
    "        </lrml:Obligation>\n",
    "\n",
    "        <lrml:Obligation>\n",
    "\n",
    "          <ruleml:Atom>\n",
    "\n",
    "            <ruleml:Rel iri=\":imprisonment\"/>\n",
    "\n",
    "            <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "            <ruleml:Ind>2 years</ruleml:Ind>\n",
    "\n",
    "          </ruleml:Atom>\n",
    "\n",
    "        </lrml:Obligation>\n",
    "\n",
    "        <lrml:Obligation>\n",
    "\n",
    "          <ruleml:Atom>\n",
    "\n",
    "            <ruleml:Rel iri=\":payPenalUnitPlusImprisonment\"/>\n",
    "\n",
    "            <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "            <ruleml:Ind>200</ruleml:Ind>\n",
    "\n",
    "            <ruleml:Ind>2 years</ruleml:Ind>\n",
    "\n",
    "          </ruleml:Atom>\n",
    "\n",
    "        </lrml:Obligation>\n",
    "\n",
    "      </lrml:SuborderList>\n",
    "\n",
    "    </lrml:PenaltyStatement>\n",
    "\n",
    "\n",
    "\n",
    "    <lrml:ReparationStatement key=\"rep1\">\n",
    "\n",
    "      <lrml:Reparation key=\"assoc1\">\n",
    "\n",
    "        <lrml:appliesPenalty keyref=\"#pen1\"/>\n",
    "\n",
    "        <lrml:toPrescriptiveStatement keyref=\"#ps1\"/>\n",
    "\n",
    "      </lrml:Reparation>\n",
    "\n",
    "    </lrml:ReparationStatement>\n",
    "\n",
    "    <lrml:ReparationStatement key=\"rep2\">\n",
    "\n",
    "      <lrml:Reparation keyref=\"#assoc1\">\n",
    "\n",
    "        <lrml:appliesPenalty keyref=\"#pen2\"/>\n",
    "\n",
    "        <lrml:toPrescriptiveStatement keyref=\"#ps1\"/>\n",
    "\n",
    "      </lrml:Reparation>\n",
    "\n",
    "    </lrml:ReparationStatement>\n",
    "\n",
    "</lrml:Statements>\n",
    "                \"\"\"\n",
    "            }\n",
    "        ]\n",
    "        example_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"human\", \"{question}\"),\n",
    "                (\"ai\", \"{answer}\"),\n",
    "            ]\n",
    "\n",
    "        )\n",
    "\n",
    "        few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "            example_prompt=example_prompt,\n",
    "            examples=examples,\n",
    "        )\n",
    "\n",
    "        final_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\",\n",
    "                 \"You are a consistent Legal Rule ML converter who takes the statute text as input and outputs the XML format for the same with reference to the documentation available at http://docs.oasis-open.org/legalruleml/legalruleml-core-spec/v1.0/legalruleml-core-spec-v1.0.html\"),\n",
    "                few_shot_prompt,\n",
    "                (\"human\", \"{question}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        llm_chain = final_prompt | hf\n",
    "\n",
    "        result = llm_chain.invoke({\"question\": section_for_conversion})\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2802096",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = instantiate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0008543f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef5bc142",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_for_conversion = \"6. Responsibilities of collection centres.\tcollect e-waste on behalf of producer or dismantler or recycler or refurbisher including those arising from orphaned products;, Provided the collection centres established by producer can also collect e-waste on behalf of dismantler, refurbisher and recycler including those arising from orphaned products, ensure that the facilities are in accordance with the standards or guidelines issued by Central Pollution Control Board from time to time;, ensure that the e-waste collected by them is stored in a secured manner till it is sent to authorised dismantler or recycler as the case may be;, ensure that no damage is caused to the environment during storage and transportation of e-waste;, maintain records in Form-2 of the e-waste handled as per the guidelines of Central Pollution Control Board and make such records available for scrutiny by the Central Pollution Control Board or the concerned State Pollution Control Board as and when asked for.\"\n",
    "\n",
    "result = send_request(hf, section_for_conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44097b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AI: <lrml:ConstitutiveStatement key=\"statuteExtract\">\n",
      "\n",
      "<ruleml:Rule closure=\"universal\">\n",
      "\n",
      "    <lrml:Paraphrase>The collection centers must collect e-waste on behalf of producers, dismantlers, recyclers, and refurbishers, including waste from orphaned products.</lrml:Paraphrase>\n",
      "\n",
      "    <ruleml:if>\n",
      "\n",
      "        <ruleml:Atom>\n",
      "\n",
      "            <ruleml:Rel iri=\":collectionCenter\"/>\n",
      "\n",
      "            <ruleml:Var>X</ruleml:Var>\n",
      "\n",
      "        </ruleml:Atom>\n",
      "\n",
      "    </ruleml:if>\n",
      "\n",
      "    <ruleml:then>\n",
      "\n",
      "      <lrml:Obligation>\n",
      "\n",
      "        <ruleml:Atom>\n",
      "\n",
      "          <ruleml:Rel iri=\":storeEWasteSecurely\"/>\n",
      "\n",
      "          <ruleml:Var>X</ruleml:Var>\n",
      "\n",
      "        </ruleml:Atom>\n",
      "\n",
      "        <ruleml:Atom>\n",
      "\n",
      "          <ruleml:Rel iri=\":ensureNoEnvironmentalDamage\"/>\n",
      "\n",
      "          <ruleml:Var>X</ruleml:Var>\n",
      "\n",
      "        </ruleml:Atom>\n",
      "\n",
      "        <ruleml:Atom>\n",
      "\n",
      "          <ruleml:Rel iri=\":maintainRecordsForm2\"/>\n",
      "\n",
      "          <ruleml:Var>X</ruleml:Var>\n",
      "\n",
      "        </ruleml:Atom>\n",
      "\n",
      "      </lrml:Obligation>\n",
      "\n",
      "    </ruleml:then>\n",
      "\n",
      "</ruleml:Rule>\n",
      "\n",
      "</lrml:ConstitutiveStatement>\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d34c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: <lrml:ConstitutiveStatement key=\"collectioncentre\">\n",
      "\n",
      "      <ruleml:Rule closure=\"universal\">\n",
      "\n",
      "    <lrml:Paraphrase>Collection centres must collect e-waste on behalf of producers, dismantlers, refurbishers, and recyclers, including waste from orphaned products.</lrml:Paraphrase>\n",
      "\n",
      "    <ruleml:if>\n",
      "\n",
      "      <ruleml:Atom>\n",
      "\n",
      "        <ruleml:Rel iri=\":establishFacility\"/>\n",
      "\n",
      "        <ruleml:Var>X</ruleml:Var>\n",
      "\n",
      "      </ruleml:Atom>\n",
      "\n",
      "    </ruleml:if>\n",
      "\n",
      "    <ruleml:then>\n",
      "\n",
      "      <lrml:SuborderList>\n",
      "\n",
      "        <lrml:Prohibition>\n",
      "\n",
      "          <ruleml:Atom>\n",
      "\n",
      "            <ruleml:Rel iri=\":storeEWasteSecurely\"/>\n",
      "\n",
      "            <ruleml:Var>X</ruleml:Var>\n",
      "\n",
      "          </ruleml:Atom>\n",
      "\n",
      "        </lrml:Prohibition>\n",
      "\n",
      "      </lrml:SuborderList>\n",
      "\n",
      "    </ruleml:then>\n",
      "\n",
      "    <ruleml:then>\n",
      "\n",
      "      <lrml:SuborderList>\n",
      "\n",
      "        <lrml:Obligation>\n",
      "\n",
      "          <ruleml:Atom>\n",
      "\n",
      "            <ruleml:Rel iri=\":transportEWasteSecurely\"/>\n",
      "\n",
      "            <ruleml:Var>X</ruleml:Var>\n",
      "\n",
      "          </ruleml:Atom>\n",
      "\n",
      "        </lrml:Obligation>\n",
      "\n",
      "      </lrml:SuborderList>\n",
      "\n",
      "    </ruleml:then>\n",
      "\n",
      "    <ruleml:then>\n",
      "\n",
      "      <lrml:SuborderList>\n",
      "\n",
      "        <lrml:Obligation>\n",
      "\n",
      "          <ruleml:Atom>\n",
      "\n",
      "            <ruleml:Rel iri=\":maintainRecordsAccordingly\"/>\n",
      "\n",
      "            <ruleml:Var>X</ruleml:Var>\n",
      "\n",
      "          </ruleml:Atom>\n",
      "\n",
      "        </lrml:Obligation>\n",
      "\n",
      "      </lrml:SuborderList>\n",
      "\n",
      "    </ruleml:then>\n",
      "\n",
      "\n",
      "    <ruleml:Rule closure=\"universal\">\n",
      "\n",
      "      <lrml:Paraphrase>Collection centres must comply with guidelines issued by Central Pollution Control Board regarding handling and disposal of e-waste.</lrml:Paraphrase>\n",
      "\n",
      "    </ruleml:Rule>\n",
      "\n",
      "</lrml:ConstitutiveStatement>\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a019fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= \"\"\"<lrml:ConstitutiveStatement key=\"statuteExtract\">\n",
    "\n",
    "<ruleml:Rule closure=\"universal\">\n",
    "\n",
    "    <lrml:Paraphrase>The collection centers must collect e-waste on behalf of producers, dismantlers, recyclers, and refurbishers, including waste from orphaned products.</lrml:Paraphrase>\n",
    "\n",
    "    <ruleml:if>\n",
    "\n",
    "        <ruleml:Atom>\n",
    "\n",
    "            <ruleml:Rel iri=\":collectionCenter\"/>\n",
    "\n",
    "            <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "        </ruleml:Atom>\n",
    "\n",
    "    </ruleml:if>\n",
    "\n",
    "    <ruleml:then>\n",
    "\n",
    "      <lrml:Obligation>\n",
    "\n",
    "        <ruleml:Atom>\n",
    "\n",
    "          <ruleml:Rel iri=\":storeEWasteSecurely\"/>\n",
    "\n",
    "          <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "        </ruleml:Atom>\n",
    "\n",
    "        <ruleml:Atom>\n",
    "\n",
    "          <ruleml:Rel iri=\":ensureNoEnvironmentalDamage\"/>\n",
    "\n",
    "          <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "        </ruleml:Atom>\n",
    "\n",
    "        <ruleml:Atom>\n",
    "\n",
    "          <ruleml:Rel iri=\":maintainRecordsForm2\"/>\n",
    "\n",
    "          <ruleml:Var>X</ruleml:Var>\n",
    "\n",
    "        </ruleml:Atom>\n",
    "\n",
    "      </lrml:Obligation>\n",
    "\n",
    "    </ruleml:then>\n",
    "\n",
    "</ruleml:Rule>\n",
    "\n",
    "</lrml:ConstitutiveStatement>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff22f15-dd1e-4bd6-bea2-9a0cdd290606",
   "metadata": {},
   "source": [
    "### Part-3-A\n",
    "\n",
    "Trying an approach for prompting using SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd296708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAGPrompt(hf):\n",
    "    \n",
    "    sys_prompt = \"\"\"You are an assistant that takes the XML generated and tweaks it in accordance with the rdfs metamodel provided to you below as context. \n",
    "        The XML is in compliance with the LegalRuleML core specification, whereas the metamodel provides an overview of what the XML should be for a particular category of XML elements.\n",
    "        \"\"\"\n",
    "    '''\n",
    "    human_prompt = \"\"\"\n",
    "    ### [INST] \n",
    "        <<SYS>>\n",
    "        {system_prompt}\n",
    "        \n",
    "        The category being implemented is defined as follows:\n",
    "        \n",
    "        {metamodel_definition}\n",
    "        \n",
    "         <</SYS>>\n",
    "        Use the following metamodel in RDFS to ensure that the XML generated is in terms of the definition of the metamodel provided in the LegalRuleML specification.\n",
    "    \n",
    "        {metamodel_XML}\n",
    "        \n",
    "    \n",
    "        ### LEGAL_XML:\n",
    "        {question} \n",
    "        [/INST]\n",
    "    \"\"\"\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    human_prompt = \"\"\"\n",
    "    ### [INST] \n",
    "        \n",
    "        The category being implemented is defined as follows:\n",
    "        \n",
    "        {metamodel_definition}\n",
    "        \n",
    "        Use the following metamodel in RDFS to ensure that the XML generated is in terms of the definition of the metamodel provided in the LegalRuleML specification.\n",
    "    \n",
    "        {metamodel_XML}\n",
    "        \n",
    "    \n",
    "        ### LEGAL_XML:\n",
    "        {question} \n",
    "        [/INST]\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    def get_relevant_metamodel(retrieverObj):\n",
    "        docs = retrieverObj.get_relevant_documents(\"query\")\n",
    "\n",
    "        docs = docs.replace('\\n', '')\n",
    "        docs = docs.replace('\\t', '')\n",
    "\n",
    "        data = json.loads(docs)\n",
    "\n",
    "        relevant_metamodel = data[2][\"deontic\"]\n",
    "        return relevant_metamodel\n",
    "\n",
    "    def get_relevant_definition(retrieverObj):\n",
    "        docs = retrieverObj.get_relevant_documents(\"query\")\n",
    "        docs = docs.replace('\\n', '')\n",
    "        docs = docs.replace('\\t', '')\n",
    "\n",
    "        data = json.loads(docs)\n",
    "\n",
    "        relevant_definition = data[2][\"description\"]\n",
    "        return relevant_definition\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Assuming sys_prompt and human_prompt are defined earlier in your code\n",
    "    template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", sys_prompt),\n",
    "        (\"human\", human_prompt)\n",
    "    ])\n",
    "    \n",
    "    #prompt=template.format_prompt()\n",
    "    \n",
    "    # Correctly initialize LLMChain with your language model handler ('hf') and the created template\n",
    "    llm_chain = LLMChain(llm=hf, prompt=template)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Llama-2-7B-Chat-GPTQ\")\n",
    "\n",
    "    # Assuming sys_prompt and human_prompt are strings containing your prompts\n",
    "    messages = [sys_prompt, human_prompt]\n",
    "\n",
    "    # Tokenize each message and sum their lengths\n",
    "    total_tokens = sum([len(tokenizer.encode(message, add_special_tokens=True)) for message in messages])\n",
    "\n",
    "    print(\"\\n\\n The prompt for input is \", template, \"\\n\\n\", \"Length is\", total_tokens, \"\\n\\n\")\n",
    "\n",
    "    \n",
    "    input_dict = {\n",
    "                  \"metamodel_definition\": metamodel_definition,\n",
    "                  \"metamodel_XML\": metamodel_XML,\n",
    "                  \"question\": text_value,\n",
    "                  }\n",
    "    \n",
    "    \n",
    "\n",
    "    # Invoke the LLMChain with the dictionary as input\n",
    "    new_text_value = llm_chain.invoke(input=input_dict)\n",
    "\n",
    "    return new_text_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c3f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metamodel_definition = \"Defeasibility is the property that a conclusion is open in principle to revision in case more evidence to the contrary is provided. Defeasible reasoning is in contrast to monotonic reasoning of propositional logic, where no revision is possible. In addition, defeasible reasoning allows reasoning in the face of contradictions, which gives rise to ex false quodlibet in propositional logic. One application of defeasible reasoning is the ability to model exceptions in a simple and natural way.\"\n",
    "metamodel_XML = \"\"\"       \n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    " <!DOCTYPE RDF [\n",
    "   <!ENTITY dcterms \"http://purl.org/dc/terms\">  \n",
    "   <!ENTITY rdf \"http://www.w3.org/1999/02/22-rdf-syntax-ns\">  \n",
    "   <!ENTITY rdfs \"http://www.w3.org/2000/01/rdf-schema\">  \n",
    "   <!ENTITY owl \"http://www.w3.org/2002/07/owl\">    \n",
    "   <!ENTITY xs \"http://www.w3.org/2001/XMLSchema\">    \n",
    "   <!ENTITY rulemm \"http://docs.oasis-open.org/legalruleml/ns/v1.0/rule-metamodel\">  \n",
    "   <!ENTITY lrmlmm \"http://docs.oasis-open.org/legalruleml/ns/v1.0/metamodel\">    \n",
    "   <!ENTITY lrmlv \"http://docs.oasis-open.org/legalruleml/ns/v1.0/vocab\">  \n",
    " ]>\n",
    "  \n",
    "  <rdfs:Class rdf:about=\"#Override\">\n",
    "    <rdfs:label>override</rdfs:label>\n",
    "    <rdfs:comment>an indication that a Legal Rule takes precedence over another Legal Rule. The ordered pair of Legal Rules is an instance in a defeasible priority relation.</rdfs:comment>\n",
    "    <rdfs:subClassOf rdf:resource=\"&rulemm;#Atom\"/>\n",
    "  </rdfs:Class>\n",
    "\n",
    "  <!-- Import from RuleML for diagramming purposes -->  \n",
    "  <rdfs:Class rdf:about=\"&rulemm;#Atom\">\n",
    "    <rdfs:subClassOf rdf:resource=\"&rulemm;#Formula\"/>\n",
    "  </rdfs:Class>\n",
    "  \n",
    "  <rdfs:Class rdf:about=\"#Strength\">\n",
    "    <rdfs:label>strength</rdfs:label>\n",
    "    <rdfs:comment>the quality of a Legal Rule to resist or not to resist a rebuttal.</rdfs:comment>\n",
    "    <rdfs:subClassOf rdf:resource=\"#Associable\"/>\n",
    "  </rdfs:Class>\n",
    "  \n",
    "\n",
    "</rdf:RDF>\n",
    "\"\"\"\n",
    "\n",
    "text_value = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ecfa3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " The prompt for input is  input_variables=['metamodel_XML', 'metamodel_definition', 'question'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an assistant that takes the XML generated and tweaks it in accordance with the rdfs metamodel provided to you below as context. \\n        The XML is in compliance with the LegalRuleML core specification, whereas the metamodel provides an overview of what the XML should be for a particular category of XML elements.\\n        ')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['metamodel_XML', 'metamodel_definition', 'question'], template='\\n    ### [INST] \\n        \\n        The category being implemented is defined as follows:\\n        \\n        {metamodel_definition}\\n        \\n        Use the following metamodel in RDFS to ensure that the XML generated is in terms of the definition of the metamodel provided in the LegalRuleML specification.\\n    \\n        {metamodel_XML}\\n        \\n    \\n        ### LEGAL_XML:\\n        {question} \\n        [/INST]\\n        '))] \n",
      "\n",
      " Length is 185 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text_value = RAGPrompt(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3e1b4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metamodel_definition': 'Defeasibility is the property that a conclusion is open in principle to revision in case more evidence to the contrary is provided. Defeasible reasoning is in contrast to monotonic reasoning of propositional logic, where no revision is possible. In addition, defeasible reasoning allows reasoning in the face of contradictions, which gives rise to ex false quodlibet in propositional logic. One application of defeasible reasoning is the ability to model exceptions in a simple and natural way.', 'metamodel_XML': '       \\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n <!DOCTYPE RDF [\\n   <!ENTITY dcterms \"http://purl.org/dc/terms\">  \\n   <!ENTITY rdf \"http://www.w3.org/1999/02/22-rdf-syntax-ns\">  \\n   <!ENTITY rdfs \"http://www.w3.org/2000/01/rdf-schema\">  \\n   <!ENTITY owl \"http://www.w3.org/2002/07/owl\">    \\n   <!ENTITY xs \"http://www.w3.org/2001/XMLSchema\">    \\n   <!ENTITY rulemm \"http://docs.oasis-open.org/legalruleml/ns/v1.0/rule-metamodel\">  \\n   <!ENTITY lrmlmm \"http://docs.oasis-open.org/legalruleml/ns/v1.0/metamodel\">    \\n   <!ENTITY lrmlv \"http://docs.oasis-open.org/legalruleml/ns/v1.0/vocab\">  \\n ]>\\n  \\n  <rdfs:Class rdf:about=\"#Override\">\\n    <rdfs:label>override</rdfs:label>\\n    <rdfs:comment>an indication that a Legal Rule takes precedence over another Legal Rule. The ordered pair of Legal Rules is an instance in a defeasible priority relation.</rdfs:comment>\\n    <rdfs:subClassOf rdf:resource=\"&rulemm;#Atom\"/>\\n  </rdfs:Class>\\n\\n  <!-- Import from RuleML for diagramming purposes -->  \\n  <rdfs:Class rdf:about=\"&rulemm;#Atom\">\\n    <rdfs:subClassOf rdf:resource=\"&rulemm;#Formula\"/>\\n  </rdfs:Class>\\n  \\n  <rdfs:Class rdf:about=\"#Strength\">\\n    <rdfs:label>strength</rdfs:label>\\n    <rdfs:comment>the quality of a Legal Rule to resist or not to resist a rebuttal.</rdfs:comment>\\n    <rdfs:subClassOf rdf:resource=\"#Associable\"/>\\n  </rdfs:Class>\\n  \\n\\n</rdf:RDF>\\n', 'question': '<lrml:ConstitutiveStatement key=\"statuteExtract\">\\n\\n<ruleml:Rule closure=\"universal\">\\n\\n    <lrml:Paraphrase>The collection centers must collect e-waste on behalf of producers, dismantlers, recyclers, and refurbishers, including waste from orphaned products.</lrml:Paraphrase>\\n\\n    <ruleml:if>\\n\\n        <ruleml:Atom>\\n\\n            <ruleml:Rel iri=\":collectionCenter\"/>\\n\\n            <ruleml:Var>X</ruleml:Var>\\n\\n        </ruleml:Atom>\\n\\n    </ruleml:if>\\n\\n    <ruleml:then>\\n\\n      <lrml:Obligation>\\n\\n        <ruleml:Atom>\\n\\n          <ruleml:Rel iri=\":storeEWasteSecurely\"/>\\n\\n          <ruleml:Var>X</ruleml:Var>\\n\\n        </ruleml:Atom>\\n\\n        <ruleml:Atom>\\n\\n          <ruleml:Rel iri=\":ensureNoEnvironmentalDamage\"/>\\n\\n          <ruleml:Var>X</ruleml:Var>\\n\\n        </ruleml:Atom>\\n\\n        <ruleml:Atom>\\n\\n          <ruleml:Rel iri=\":maintainRecordsForm2\"/>\\n\\n          <ruleml:Var>X</ruleml:Var>\\n\\n        </ruleml:Atom>\\n\\n      </lrml:Obligation>\\n\\n    </ruleml:then>\\n\\n</ruleml:Rule>\\n\\n</lrml:ConstitutiveStatement>', 'text': \"\\nThank you for providing the LegalRuleML metamodel and the example XML. I'll do my best to assist you in generating the desired XML based on the metamodel and the information provided.\\nTo begin, could you please clarify what kind of XML you would like me to generate? Are you looking for a single XML element or a set of related elements? Additionally, please provide any additional context or requirements that might be helpful for me to understand your request better.\"}\n"
     ]
    }
   ],
   "source": [
    "print(new_text_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6556d9-837e-4974-8778-5c3e282d5077",
   "metadata": {},
   "source": [
    "### Part-3-B\n",
    "Prompting the ChatPromptTemplate by adding System Prompt to Llama2's instruction prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ec92757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAGPrompt(hf):\n",
    "    \n",
    "    sys_prompt = \"\"\"You are an assistant that takes the XML generated and tweaks it in accordance with the rdfs metamodel provided to you below as context. \n",
    "        The XML is in compliance with the LegalRuleML core specification, whereas the metamodel provides an overview of what the XML should be for a particular category of XML elements.\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    #Since the context window did not have system_prompt, it was returning a deficient output (asking for more information or context)\n",
    "    # In this strategy, the human_prompt itself is being used to provide the system prompt as context, using the tags accepted by Llama2 (see https://huggingface.co/blog/llama2)\n",
    "    \n",
    "    human_prompt = \"\"\"\n",
    "    ### [INST] \n",
    "        <<SYS>>\n",
    "        {system_prompt}\n",
    "        \n",
    "        The category being implemented is defined as follows:\n",
    "        \n",
    "        {metamodel_definition}\n",
    "        \n",
    "         <</SYS>>\n",
    "        Use the following metamodel in RDFS to ensure that the XML generated is in terms of the definition of the metamodel provided in the LegalRuleML specification.\n",
    "    \n",
    "        {metamodel_XML}\n",
    "        \n",
    "    \n",
    "        ### LEGAL_XML:\n",
    "        {question} \n",
    "        [/INST]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    human_prompt = \"\"\"\n",
    "    ### [INST] \n",
    "        \n",
    "        The category being implemented is defined as follows:\n",
    "        \n",
    "        {metamodel_definition}\n",
    "        \n",
    "        Use the following metamodel in RDFS to ensure that the XML generated is in terms of the definition of the metamodel provided in the LegalRuleML specification.\n",
    "    \n",
    "        {metamodel_XML}\n",
    "        \n",
    "    \n",
    "        ### LEGAL_XML:\n",
    "        {question} \n",
    "        [/INST]\n",
    "        \"\"\"\n",
    "    '''\n",
    "    \n",
    "    def get_relevant_metamodel(retrieverObj):\n",
    "        docs = retrieverObj.get_relevant_documents(\"query\")\n",
    "\n",
    "        docs = docs.replace('\\n', '')\n",
    "        docs = docs.replace('\\t', '')\n",
    "\n",
    "        data = json.loads(docs)\n",
    "\n",
    "        relevant_metamodel = data[2][\"deontic\"]\n",
    "        return relevant_metamodel\n",
    "\n",
    "    def get_relevant_definition(retrieverObj):\n",
    "        docs = retrieverObj.get_relevant_documents(\"query\")\n",
    "        docs = docs.replace('\\n', '')\n",
    "        docs = docs.replace('\\t', '')\n",
    "\n",
    "        data = json.loads(docs)\n",
    "\n",
    "        relevant_definition = data[2][\"description\"]\n",
    "        return relevant_definition\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Assuming sys_prompt and human_prompt are defined earlier in your code\n",
    "    template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", sys_prompt),\n",
    "        (\"human\", human_prompt)\n",
    "    ])\n",
    "    \n",
    "    #prompt=template.format_prompt()\n",
    "    \n",
    "    # Correctly initialize LLMChain with your language model handler ('hf') and the created template\n",
    "    llm_chain = LLMChain(llm=hf, prompt=template)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Llama-2-7B-Chat-GPTQ\")\n",
    "\n",
    "    # Assuming sys_prompt and human_prompt are strings containing your prompts\n",
    "    messages = [sys_prompt, human_prompt]\n",
    "\n",
    "    # Tokenize each message and sum their lengths\n",
    "    total_tokens = sum([len(tokenizer.encode(message, add_special_tokens=True)) for message in messages])\n",
    "\n",
    "    print(\"\\n\\n The prompt for input is \", template, \"\\n\\n\", \"Length is\", total_tokens, \"\\n\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "    input_dict = {\n",
    "                  \"system_prompt\": sys_prompt,\n",
    "                  \"metamodel_definition\": metamodel_definition,\n",
    "                  \"metamodel_XML\": metamodel_XML,\n",
    "                  \"question\": text_value,\n",
    "                  }\n",
    "\n",
    "    # Invoke the LLMChain with the dictionary as input\n",
    "    new_text_value = llm_chain.invoke(input=input_dict)\n",
    "\n",
    "    return new_text_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67221448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " The prompt for input is  input_variables=['metamodel_XML', 'metamodel_definition', 'question', 'system_prompt'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an assistant that takes the XML generated and tweaks it in accordance with the rdfs metamodel provided to you below as context. \\n        The XML is in compliance with the LegalRuleML core specification, whereas the metamodel provides an overview of what the XML should be for a particular category of XML elements.\\n        ')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['metamodel_XML', 'metamodel_definition', 'question', 'system_prompt'], template='\\n    ### [INST] \\n        <<SYS>>\\n        {system_prompt}\\n        \\n        The category being implemented is defined as follows:\\n        \\n        {metamodel_definition}\\n        \\n         <</SYS>>\\n        Use the following metamodel in RDFS to ensure that the XML generated is in terms of the definition of the metamodel provided in the LegalRuleML specification.\\n    \\n        {metamodel_XML}\\n        \\n    \\n        ### LEGAL_XML:\\n        {question} \\n        [/INST]\\n    '))] \n",
      "\n",
      " Length is 206 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_text_value = RAGPrompt(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e6d4c-126b-4b43-b997-2bc874a25bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1724d820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system_prompt': 'You are an assistant that takes the XML generated and tweaks it in accordance with the rdfs metamodel provided to you below as context. \\n        The XML is in compliance with the LegalRuleML core specification, whereas the metamodel provides an overview of what the XML should be for a particular category of XML elements.\\n        ', 'metamodel_definition': 'Defeasibility is the property that a conclusion is open in principle to revision in case more evidence to the contrary is provided. Defeasible reasoning is in contrast to monotonic reasoning of propositional logic, where no revision is possible. In addition, defeasible reasoning allows reasoning in the face of contradictions, which gives rise to ex false quodlibet in propositional logic. One application of defeasible reasoning is the ability to model exceptions in a simple and natural way.', 'metamodel_XML': '       \\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n <!DOCTYPE RDF [\\n   <!ENTITY dcterms \"http://purl.org/dc/terms\">  \\n   <!ENTITY rdf \"http://www.w3.org/1999/02/22-rdf-syntax-ns\">  \\n   <!ENTITY rdfs \"http://www.w3.org/2000/01/rdf-schema\">  \\n   <!ENTITY owl \"http://www.w3.org/2002/07/owl\">    \\n   <!ENTITY xs \"http://www.w3.org/2001/XMLSchema\">    \\n   <!ENTITY rulemm \"http://docs.oasis-open.org/legalruleml/ns/v1.0/rule-metamodel\">  \\n   <!ENTITY lrmlmm \"http://docs.oasis-open.org/legalruleml/ns/v1.0/metamodel\">    \\n   <!ENTITY lrmlv \"http://docs.oasis-open.org/legalruleml/ns/v1.0/vocab\">  \\n ]>\\n  \\n  <rdfs:Class rdf:about=\"#Override\">\\n    <rdfs:label>override</rdfs:label>\\n    <rdfs:comment>an indication that a Legal Rule takes precedence over another Legal Rule. The ordered pair of Legal Rules is an instance in a defeasible priority relation.</rdfs:comment>\\n    <rdfs:subClassOf rdf:resource=\"&rulemm;#Atom\"/>\\n  </rdfs:Class>\\n\\n  <!-- Import from RuleML for diagramming purposes -->  \\n  <rdfs:Class rdf:about=\"&rulemm;#Atom\">\\n    <rdfs:subClassOf rdf:resource=\"&rulemm;#Formula\"/>\\n  </rdfs:Class>\\n  \\n  <rdfs:Class rdf:about=\"#Strength\">\\n    <rdfs:label>strength</rdfs:label>\\n    <rdfs:comment>the quality of a Legal Rule to resist or not to resist a rebuttal.</rdfs:comment>\\n    <rdfs:subClassOf rdf:resource=\"#Associable\"/>\\n  </rdfs:Class>\\n  \\n\\n</rdf:RDF>\\n', 'question': '<lrml:ConstitutiveStatement key=\"statuteExtract\">\\n\\n<ruleml:Rule closure=\"universal\">\\n\\n    <lrml:Paraphrase>The collection centers must collect e-waste on behalf of producers, dismantlers, recyclers, and refurbishers, including waste from orphaned products.</lrml:Paraphrase>\\n\\n    <ruleml:if>\\n\\n        <ruleml:Atom>\\n\\n            <ruleml:Rel iri=\":collectionCenter\"/>\\n\\n            <ruleml:Var>X</ruleml:Var>\\n\\n        </ruleml:Atom>\\n\\n    </ruleml:if>\\n\\n    <ruleml:then>\\n\\n      <lrml:Obligation>\\n\\n        <ruleml:Atom>\\n\\n          <ruleml:Rel iri=\":storeEWasteSecurely\"/>\\n\\n          <ruleml:Var>X</ruleml:Var>\\n\\n        </ruleml:Atom>\\n\\n        <ruleml:Atom>\\n\\n          <ruleml:Rel iri=\":ensureNoEnvironmentalDamage\"/>\\n\\n          <ruleml:Var>X</ruleml:Var>\\n\\n        </ruleml:Atom>\\n\\n        <ruleml:Atom>\\n\\n          <ruleml:Rel iri=\":maintainRecordsForm2\"/>\\n\\n          <ruleml:Var>X</ruleml:Var>\\n\\n        </ruleml:Atom>\\n\\n      </lrml:Obligation>\\n\\n    </ruleml:then>\\n\\n</ruleml:Rule>\\n\\n</lrml:ConstitutiveStatement>', 'text': ' I can assist you by providing the adjustments required to convert the given XML into RDFS based on the Rules Metamodel (RuleML) specified in the LegalRuleML specification. Here is the modified XML according to the guidelines specified:\\n     <rdfs:Class rdf:about=\"#Override\">\\n        <rdfs:label> override</rdfs:label>\\n        <rdfs:comment>a sign that a legal rule outranks another legal rule</rdfs:comment>\\n        <rdfs:subClassOf rdf:resource=\"&rulemm;#Atom\"></rdfs:subClassOf>\\n     </rdfs:Class>\\n\\n     <rdfs:Class rdf:about=\"#Strength\">\\n        <rdfs:label>strength</rdfs:label>\\n        <rdfs:comment>the capacity of a legal rule to combat or counteract a counterargument</rdfs:comment>\\n        <rdfs:subClassOf rdf:resource=\"#Associable\"></rdfs:subClassOf>\\n     </rdfs:Class>\\n\\n     <lrml:ConstitutiveStatement key=\"statuteExtract\">\\n\\n        <ruleml:Rule closure=\"universal\">\\n\\n            <ruleml:Paraphrase>The collection centers must gather e-waste on behalf of manufacturers, disassemblers, recyclers, and refurbishers, including waste from abandoned items.</ruleml:Paraphrase>\\n\\n            <ruleml:if>\\n\\n                <ruleml:Atom>\\n\\n                    <ruleml:Rel iri=\":collectionCenter\"/>\\n\\n                    <ruleml:Var>X</ruleml:Var>\\n\\n                </ruleml:Atom>\\n\\n            </ruleml:if>\\n\\n            <ruleml:then>\\n\\n              <lrml:Obligation>\\n\\n                 <ruleml:Atom>\\n\\n                   <ruleml:Rel iri=\":storeEWasteSecurely\"/>\\n\\n                   <ruleml:Var>X</ruleml:Var>\\n\\n               </ruleml:Atom>\\n\\n               <ruleml:Atom>\\n\\n                   <ruleml:Rel iri=\":ensureNoEnvironmentalDamage\"/>\\n\\n                   <ruleml:Var>X</ruleml:Var>\\n\\n               </ruleml:Atom>\\n\\n               <ruleml:Atom>\\n\\n                 <ruleml:Rel iri=\":maintainRecordsForm2\"/>\\n\\n                 <ruleml:Var>X</ruleml:Var>\\n\\n             </ruleml:Atom>\\n\\n          </lrml:Obligation>\\n\\n        </ruleml:then>\\n\\n</ruleml:Rule>\\n\\n</lrml:ConstitutiveStatement>\\n\\nI have made several adjustments to the provided XML based on the Rules Metamodel (RuleML) defined in the LegalRuleML specification. These changes are highlighted using angle brackets.\\n     * I changed the class names to match the Rules Metamodel (RuleML) definition.\\n     * For each class, I added the proper subClassOf relationship to the RDFS vocabulary.\\n     * I included the necessary comments for each class to explain their significance.\\n\\nPlease let me know if there are any further adjustments you want me to make!'}\n"
     ]
    }
   ],
   "source": [
    "print(new_text_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7304a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Schematise-dev",
   "language": "python",
   "name": "schematise-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
